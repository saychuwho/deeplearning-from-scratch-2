{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import config\n",
    "# GPU에서 실행하려면 아래 주석을 해제하세요(CuPy 필요).\n",
    "# ===============================================\n",
    "# config.GPU = True\n",
    "# ===============================================\n",
    "import pickle\n",
    "from trainer import Trainer\n",
    "from optimizer import Adam\n",
    "\n",
    "from util import *\n",
    "from dataset import ptb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 순환 신경망(RNN)\n",
    "\n",
    "지금까지 본 신경망들은 흐름이 단방향인 **feed forward 신경망**이었다. feed forward 신경망은 구성이 단순해서 이해하기 쉽지만, 시계열 데이터의 패턴을 충분히 학습할 수 없다. 그래서 순환 신경망(Recurrent Neural Network, RNN)이 나왔다.\n",
    "\n",
    "이번 장에서는 피드포워드 신경망의 문제점을 지적하고, RNN이 대안이 될 수 있는 이유에 대해 다뤄본다. 또한, RNN 구조를 알아보고 파이썬으로 구현해볼 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 확률과 언어 모델\n",
    "\n",
    "이번 장에서는 word2vec을 복습해보고, 자연어에 관한 현상을 '확률'로 기술해보고, 언어를 확률로 다루는 '언어 모델'에 대해 설명해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 word2vec을 확률 관점에서 바라보자\n",
    "\n",
    "$w_1, w_2, ..., w_T$라는 단어들의 sequence로 구성된 corpus가 있을 때, $t$번째 단어를 target, $t-1, t+1$ 번째 단어를 'contexts'라고 하면, CBOW 모델의 목표는 $w_{t-1}$과 $w_{t+1}$로부터 $w_t$를 추측하는 것이다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-1.png\" width=\"60%\">\n",
    "\n",
    "이때, $w_{t-1}$과 $w_{t+1}$이 주어졌을 때, target이 $w_t$가 될 확률은 다음과 같이 나타낼 수 있다.\n",
    "\n",
    "$$\n",
    "P(w_t|w_{t-1}, w_{t+1})\n",
    "$$\n",
    "\n",
    "CBOW 모델은 위 확률을 반환한다. (책의 표현을 빌리면 \"사후 확률을 모델링합니다.\")\n",
    "\n",
    "context를 왼쪽 윈도우로 한정해보면, 다음 확률이 나온다. (왼쪽 윈도우로 한정짓는다는 거는 아래 그림 상황을 본다는 의미이다.)\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-2.png\" width=\"60%\">\n",
    "\n",
    "$$\n",
    "P(w_t|w_{t-2}, w_{t-1})\n",
    "$$\n",
    "\n",
    "위 확률을 CBOW 모델의 cross-entropy loss에 적용하면 다음 수식이 나온다\n",
    "\n",
    "$$\n",
    "L = -\\log P(w_t|w_{t-2}, w_{t-1})\n",
    "$$\n",
    "\n",
    "CBOW 모델의 학습은 loss function을 최소화하는 가중치 매개변수를 찾는 과정이다. CBOW 모델의 원래 목적인 \"context를 이용해 target을 찾는다\"를 학습하다 보면, 부산물로 단어의 의미가 인코딩된 '단어의 분산 표현'을 가중치 매개변수로부터 얻을 수 있다.\n",
    "\n",
    "CBOW 모델의 원래 기능인 \"context를 이용해 target을 찾기\"와 확률 $P(w_t|w_{t-2}, w_{t-1})$는 '언어 모델'에서 등장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 언어 모델\n",
    "\n",
    "**언어 모델(Language Model)**은 특정 단어 sequence에 대해, 그 sequence가 일어날 확률을 반환한다.\n",
    "\n",
    "언어 모델을 수식적으로 나타내보자. $w_1, w_2, ..., w_m$이라는 m개의 단어로 이루어진 문장이 있을 때, 이 단어들이 순서대로 출현할 확률은 동시확률 $P(w_1, w_2, ..., w_m)$으로 나타낼 수 있다.\n",
    "\n",
    "이 동시확률은 다음과 같이 분해할 수 있다.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    P(w_1, w_2, ..., w_m) &= P(w_m|w_1, w_2, ..., w_{m-1})P(w_m|w_1, w_2, ..., w_{m-1}) \\\\\n",
    "                          &\\quad \\cdots P(w_3|w_1, w_2)P(w_2|w_1) \\\\\n",
    "                          &= \\prod_{t=1}^{m} P(w_t|w_1, ..., w_{t-1})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "위 식의 결과는 아래 확률의 곱셈정리로부터 유도된다. 확률의 곱셈 정리는 '$A$와 $B$가 모두 일어날 확률은 $B$가 일어날 확률과 $B$가 일어난 후 $A$가 일어날 확률을 곱한 값과 같다'이다. \n",
    "\n",
    "$$\n",
    "P(A, B) = P(A|B)P(B)\n",
    "$$\n",
    "\n",
    "우리의 목표인 동시확률 $P(w_1, w_2, ..., w_m)$을 사후확률의 곱인 $\\prod P(w_t|w_1, ..., w_{t-1})$로 나타냈다. 여기서 사후확률 $P(w_t|w_1, ..., w_{t-1})$은 target 단어보다 왼쪽에 있는 모든 단어를 context로 했을 때의 확률과 동일하다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-3.png\" width=\"60%\">\n",
    "\n",
    "우리의 목표는 이제 $P(w_t|w_1, ..., w_{t-1})$를 얻는 것이다. 이 확률을 구하면 언어 모델의 동시확률을 구할 수 있기 때문이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 CBOW 모델을 언어 모델로?\n",
    "\n",
    "word2vec의 CBOW 모델을 언어 모델에 적용한다면, context의 크기를 특정 값으로 한정지은 후, 근사적으로 나타낼 수 있다.\n",
    "\n",
    "$$\n",
    "P(w_1, w_2, ..., w_m) = \\prod_{t=1}^{m} P(w_t|w_1, ..., w_{t-1}) \\approx \\prod_{t=1}^{m} P(w_t|w_{t-2}, w_{t-1})\n",
    "$$\n",
    "\n",
    "> NOTE: 위 수식에서 CBOW 모델은 **'직전 두 개의 단어에 의해 다음 단어가 결정되는'** 모델이므로, **2 step markov chain**이라 볼 수 있다.\n",
    "\n",
    "하지만 근사를 할 수 있다고 해도, 결국 context의 길이가 한정되어 있다. 또한, CBOW 모델에서는 context 안의 단어 순서들이 무시된다는 한계가 있다. (CBOW의 약어 Continuous Bag-Of-Word에서 bag라는 표현에는 순서는 무시된다는 뜻 또한 같이 있다.). 아래 그림에서 CBOW 모델을 보면, context 속 단어 벡터들이 은닉층에서 더해지기 때문에, 단어 사이의 순서는 무시되는 것을 알 수 있다. \n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-5.png\" width=\"60%\">\n",
    "\n",
    "위 그림의 오른쪽처럼 은닉층에서 두 단어를 연결해 맥락을 고려할 수 있도록 만들 수 있지만(Neural Probabilistic Language Model이 이 전략을 사용한다), 이는 매개변수가 늘어난다는 점에서 비효율적이다. 이때 RNN이 등장한다.\n",
    "\n",
    "> WARNING: 실제로는 RNN을 이용한 언어 모델이 2010년에 나오고, word2vec은 2013년에 나왔다. word2vec은 단어의 분산 표현을 얻을 목적으로 고안되어서 실제로 언어 모델에서 사용되지는 않는다. 이 책에서도 RNN의 매력을 보여주기 위해서 억지로 word2vec의 CBOW 모델로 언어 모델을 만들어 본 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 RNN이란"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 순환하는 신경망\n",
    "\n",
    "순환하기 위해서는 '닫힌 경로' 혹은 '순환하는 경로'가 필요하다. '순환하는 경로'가 있어야 데이터가 같은 장소를 반복해서 지나가고, 데이터가 순환하면서 정보가 갱신된다.\n",
    "\n",
    "RNN에는 데이터가 순환하는 경로가 있다. 데이터가 순환되기 때문에 과거의 정보를 기억하는 것도 가능하고, 최신 데이터로 갱신되는 것도 가능하다. RNN 계층은 다음과 같이 표현할 수 있다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-7.png\" width=\"60%\">\n",
    "\n",
    "위에서 보이듯, RNN 계층은 순환하는 경로가 있다. 그리고 $\\mathbf{x}_t$를 입력받는데, 여기서 $t$는 시각을 의미한다. 이는 시계열 데이터 $(\\mathbf{x}_0, \\mathbf{x}_1, \\cdots, \\mathbf{x}_t, \\cdots)$가 RNN 계층에 들어오는 것을 나타낸다. 입력에 대응한 시계열 출력 $(\\mathbf{h}_0, \\mathbf{h}_1, \\cdots, \\mathbf{h}_t, \\cdots)$도 나온다. \n",
    "\n",
    "입력 $\\mathbf{x}_t$는 벡터라고 가정한다. 문장을 다룬다고 할 때, 각 단어의 분산 표현이 $\\mathbf{x}_t$가 되고, 분산 표현이 RNN 계층에 입력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 순환 구조 펼치기\n",
    "\n",
    "RNN 구조를 펼치면 우리가 알고 있는 feed forward 신경망처럼 보인다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-8.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: 시계열 데이터는 시간 방향으로 데이터가 나열된다. 이때, 시계열 데이터의 인덱스를 가리킬 때는 '시각'이라는 용어를 사용한다.\n",
    "\n",
    "RNN 계층은 계층 입력과 이전 시각의 출력을 바탕으로 현재 출력을 계산한다. 이때 계산식은 다음과 같다.\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_t = \\tanh (\\mathbf{h}_{t-1}\\mathbf{W}_{\\mathbf{h}}+\\mathbf{x}_t \\mathbf{W}_{\\mathbf{x}} + \\mathbf{b})\n",
    "$$\n",
    "\n",
    "RNN에는 입력을 출력으로 변환하기 위한 가중치 $\\mathbf{W}_{\\mathbf{x}}$와, 이전 출력을 다음 출력으로 변환하기 위한 가중치 $\\mathbf{W}_{\\mathbf{h}}$, 두 개의 가중치가 있다. $\\mathbf{b}$는 편향이다. 여기서 $\\mathbf{h}, \\mathbf{x}$는 행벡터이다.\n",
    "\n",
    "행렬곱 연산 뒤에 $\\tanh$ 함수 거쳐 최종 출력이 나온다. 이 출력은 다음 출력을 만들 때도 사용되고, 현재 시각의 출력이기도 하다.\n",
    "\n",
    "현재의 출력($\\mathbf{h}_t$)은 한 시각 이전의 출력($\\mathbf{h}_{t-1}$)을 바탕으로 나온다. 이를 다르게 보면, RNN은 $\\mathbf{h}$라는 '상태(state)'를 가지고 있고, 위의 식을 통해 갱신된다고 볼 수 있다. 그래서 RNN 계층을 '상태를 가지는 계층', '메모리가 있는 계층'이라고 말한다.\n",
    "\n",
    "> NOTE: 많은 문헌에서 RNN의 출력 $\\mathbf{h}$를 hidden state 또는 hidden state vector라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 BPTT\n",
    "\n",
    "RNN 계층을 펼친 사진을 보면, 일반적인 feed forward 신경망처럼 back propagation을 통해 학습할 수 있다는 것을 알 수 있다. 이때 오차역전파법을 **BPTT(BackPropagation Through Time)**라고 부른다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-10.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BPTT를 이용해 RNN을 학습시키면 될 것 같지만, 긴 시계열 데이터를 학습 할 때 문제를 해결해야 한다. 시계열 데이터가 길어질 수록 컴퓨팅 자원이 증가하기 때문이다. BPTT는 이전 시각의 데이터를 가지고 있어야 하기 때문에 시계열 데이터가 길어질수록 메모리 사용량 또한 많아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4 Truncated BPTT\n",
    "\n",
    "큰 시계열 데이터를 다룰 때는 역전파 단계를 적당히 끊는다. 너무 길어진 신경망을 적당히 끊어서 작은 신경망 여러개로 자른 다음, 작은 신경망에서 오차역전파법을 수행하는 기법을 **Truncated BPTT**라고 부른다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-11.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Truncated BPTT를 사용하는 이유는 일반적인 BPTT를 이용하면 큰 시계열 데이터를 다룰 때 컴퓨팅 자원 문제도 있지만, 계층이 길어질수록 gradient vanishing 문제도 발생하기 때문이다. \n",
    "\n",
    "여기서 주의할 점은 역전파의 연결만 끊는 것이지, 순전파는 그대로 유지해야 한다는 점이다. RNN을 학습시킬 때는 데이터를 sequential하게 입력해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncated BPTT의 전체 흐름은 다음과 같다.\n",
    "\n",
    "1) 첫 번째 블록 입력 데이터 $\\mathbf{x}_0, \\cdots , \\mathbf{x}_9$를 RNN 계층에 제공한다.\n",
    "2) 첫 번째 블록의 오차역전파법을 수행한다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-12.png\" width=\"60%\">\n",
    "\n",
    "3) 두 번째 블록 입력 데이터 $\\mathbf{x}_10, \\cdots , \\mathbf{x}_19$를 RNN 계층에 제공한다. 이때, 이전 블록의 hidden state $\\mathbf{h}_9$를 같이 주어서 순전파의 흐름은 끊기지 않도록 해야 한다.\n",
    "4) 두 번째 블록의 오차역전파법을 수행한다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-13.png\" width=\"60%\">\n",
    "\n",
    "5) 이 흐름을 반복한다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-14.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.5 Truncated BPTT의 미니배치 학습\n",
    "\n",
    "지금까지 Truncated BPTT에서는 미니배치 크기가 1인 경우에 대해 생각했다. 미니배치 학습을 수행할 때도 데이터를 순서대로 제공해야 한다. \n",
    "\n",
    "길이가 1000인 시계열 데이터에서, 시각의 길이를 10 단위로 Truncated BPTT를 수행할 때, 미니 배치 크기를 두 개로 구성한다고 하면, 첫 번째 미니 배치 데이터는 시각이 0인 데이터부터 순서대로 제공하고, 두 번째 미니 배치 데이터는 시각이 500인 데이터부터 순서대로 제공한다. 이를 그림으로 정리하면 다음과 같다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-15.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미니배치 학습을 수행할 때는 \"각 미니배치의 시작 위치를 offset으로 옮겨준 후 순서대로 데이터를 제공\"하면 된다. 데이터를 입력하다가 끝에 도달하면 다시 처음부터 입력하면 된다.\n",
    "\n",
    "데이터 제공 방법을 정리하면 다음 두 사항을 지키면 된다\n",
    "- 데이터를 순서대로 제공하기\n",
    "- 미니배치별로 데이터를 제공하는 시작 위치를 옮기기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 RNN 구현\n",
    "\n",
    "우리가 구현해야 할 계층은 다음 두 계층이다.\n",
    "\n",
    "- RNN 계층: 한 시각에서 RNN의 순전파, 역전파를 처리하는 계층\n",
    "- Time RNN 계층: T개 단계분의 RNN 작업을 한꺼번에 처리하는 계층\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-17.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 RNN 계층 구현\n",
    "\n",
    "RNN의 순전파 식은 다음과 같다.\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_t = \\tanh (\\mathbf{h}_{t-1}\\mathbf{W}_{\\mathbf{h}}+\\mathbf{x}_t \\mathbf{W}_{\\mathbf{x}} + \\mathbf{b})\n",
    "$$\n",
    "\n",
    "여기에 미니배치를 고려해야 하니, $\\mathbf{x}_t, \\mathbf{h}_t$에는 각 샘플 데이터를 행 방향에 저장한다. 미니배치 크기를 $N$, 입력 벡터 차원 수를 $D$, hidden state 차원수가 $H$라면, 위 순전파 식에서 행렬의 형상을 다음과 같이 나타낼 수 있다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-18.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여담: parameter를 따로 분리해서 모아놓는 게, optimizer를 따로 만들 수 있어서 유리한 구조이다. gradient랑 거기에 맞는 weight를 주면 그에 맞춰서 계산할 수 있으니까. pytorch에서도 optimizer에 network의 parameter를 따로 주니까. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/common/time_layers.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-21\n",
    "\n",
    "Modified to work on jupyter notebook\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "from np import * \n",
    "from layers import *\n",
    "from functions import sigmoid\n",
    "\n",
    "\n",
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        \n",
    "        # 순전파 수식을 그대로 구현했다\n",
    "        t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b\n",
    "        h_next = np.tanh(t)\n",
    "\n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "\n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "\n",
    "        dt = dh_next * (1 - h_next ** 2)    # tanh의 역전파\n",
    "        db = np.sum(dt, axis=0)             # b(repeat 노드)의 역전파\n",
    "        dWh = np.dot(h_prev.T, dt)          # Wh (matmul 노드)의 역전파\n",
    "        dh_prev = np.dot(dt, Wh.T)          # h_prev (matmul 노드)의 역전파\n",
    "        dWx = np.dot(x.T, dt)               # Wx (matmul 노드)의 역전파\n",
    "        dx = np.dot(dt, Wx.T)               # x (matmul 노드)의 역전파\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN의 역전파는 RNN 순전파의 계산 그래프를 보면 쉽게 파악할 수 있다. 편향 $\\mathbf{b}$에는 Repeat 노드가 사용되었다. \n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-19.png\" width=\"60%\">\n",
    "\n",
    "역전파는 각각의 노드에 해당하는 역전파를 수행해주면 구할 수 있다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-20.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "덧셈 노드는 들어온 기울기를 분배하고, Repeat 노드는 들어온 기울기들을 더한다.\n",
    "\n",
    "matmul 노드의 역전파는 다음과 같다.\n",
    "\n",
    "<img src=\"./img/memo-5-3-1-matmul-node.jpg\" width=\"50%\">\n",
    "\n",
    "위 계산 그래프에 적용하면 다음과 같이 정리해볼 수 있다.\n",
    "\n",
    "<img src=\"./img/memo-5-3-1-backprop.jpg\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Time RNN 계층 구현\n",
    "\n",
    "책하고 코드를 같이 보면서 이해하는 게 더 빠르게 이해하는 방법인거 같다.\n",
    "\n",
    "책의 그림에서는 펼쳐져서 마치 여러개를 구현한 것처럼 보이지만, 실제로는 동일한 parameter를 이용해서 반복되게 구현되어 있다. 혼동하지 말자. \n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-24.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time RNN을 왜 구현하는가에 대한 고민을 해봤고, 다음 결론을 냈다.\n",
    "\n",
    "- Time RNN의 입력 크기만큼 순서대로 시계열 데이터가 들어간다.\n",
    "- 순전파시에 Time RNN의 stateful이 True이면, Time RNN은 이전 hidden state를 저장하고 있다가 순전파 시에 활용하니, 결과적으로 순전파 시에는 신경망이 연결되어 있다.\n",
    "- 역전파시에는 Time RNN 단위로 역전파가 이루어지므로, Truncated BPTT를 수행한다고 볼 수 있다.\n",
    "- 결과적으로, Time RNN 방식은 전체 시계열 데이터를 다룰 수 있으면서, Truncated BPTT를 이용한 역전파 또한 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/common/time_layers.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-21\n",
    "\n",
    "Modified to work on jupyter notebook\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.dh = None, None    # hidden state self.h를 보관하고 있다.\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "\n",
    "        self.layers = []\n",
    "\n",
    "        hs = np.empty((N, T, H), dtype='f') # hs를 저장하기 위해 선언한다.\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:, t, :], self.h)\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)   # backward()에서 사용하기 위해 forward 시 사용한 layer들을 저장한다.\n",
    "\n",
    "        return hs\n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = Wx.shape\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]       # RNN에서 각각 Wh, Wx, b의 기울기이다.\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:, t, :] + dh)  # dh_t + dh_next\n",
    "            dxs[:, t, :] = dx\n",
    "\n",
    "            \"\"\" \n",
    "            이 연산을 하게 되면 각 RNN 계층별로 계산된 Wh, Wx, b의 기울기가 모든 RNN 계층에 대해 다 더해진다.  \n",
    "            \"\"\"\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad   \n",
    "\n",
    "        \"\"\" \n",
    "        각 RNN 계층별로 계산한 뒤 모두 더한 Wh, Wx, b의 기울기를 덮어씌운다.  \n",
    "        \"\"\"\n",
    "        for i, grad in enumerate(grads):\n",
    "            \"\"\" \n",
    "            한참을 고민했는데 ...의 의미에 대해서, 이거는 다음과 같다. \n",
    "            self.grads[0]은 Wx의 기울기에 해당하다. 이때, grad는 모든 RNN 계층에서 얻은 Wx의 기울기 합이다. \n",
    "            둘 다 shape이 동일하니, shape을 지정하는 부분이 [...]라고 생각하면 된다.\n",
    "            \"\"\"\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 시계열 데이터 처리 계층 구현\n",
    "\n",
    "이번 장에서는 시계열 데이터를 처리하는 계층을 몇 개 더 만들어본다. 그리고 RNN을 사용한 언어모델, RNN Language Model, RNNLM을 만들기 위해 나아갈 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 RNNLM의 전체 그림\n",
    "\n",
    "가장 간단한 RNNLM을 나타낸 그림은 다음과 같다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-25.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNLM의 흐름은 다음과 같다.\n",
    "\n",
    "- 여기서 Embedding 계층은 단어ID를 받으면 단어의 분산 표현(단어 벡터)로 바꾼다. \n",
    "- 그리고 분산 표현이 RNN 계층으로 들어간다. \n",
    "- RNN 계층이 위로 출력한 hidden state는 Affine 계층을 거쳐 Softmax 계층으로 전해진다.\n",
    "\n",
    "RNNLM은 지금까지 입력된 단어를 '기억'하고, 그걸 바탕으로 다음에 출현할 단어를 예측한다. 다시 정리하면, 입력 단어가 들어오면, 다음에 올 단어를 예측해 추정한다. 그래서 softmax 계층이 존재하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 Time 계층 구현\n",
    "\n",
    "시계열 데이터를 한꺼번에 처리하는 Time Embedding, Time Affine 계층을 구현해봤다. 이 계층들을 조합하면, 다음과 같은 그림대로 신경망을 구현할 수 있다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-27.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Affine 계층은 Affine 계층 T개를 준비해서, 각각의 결과를 반환하면 된다.\n",
    "\n",
    "아래 코드의 흐름을 분석해보면, 다음과 같다.\n",
    "\n",
    "<img src=\"./img/memo-5-4-2-time-affine.jpg\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/common/time_layers.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-21\n",
    "\n",
    "Modified to work on jupyter notebook\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class TimeAffine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        \"\"\"  \n",
    "        각 시계열 데이터를 하나의 행렬로 합쳐서 연산한다.\n",
    "        \"\"\"\n",
    "        rx = x.reshape(N*T, -1)         # 시계열 데이터를 N*T x D 모양의 행렬로 만든다.\n",
    "        out = np.dot(rx, W) + b         # 바뀐 행렬과 가중치, 편향을 이용해 출력을 만든다.\n",
    "        self.x = x\n",
    "        return out.reshape(N, T, -1)    # 실제로는 N, T, D로 결과를 반환해야 하니 reshape을 통해 다시 모양을 바꾼다.\n",
    "\n",
    "    def backward(self, dout):\n",
    "        x = self.x\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        dout = dout.reshape(N*T, -1)    # 들어온 기울기들의 모양을 바꿔준다.\n",
    "        rx = x.reshape(N*T, -1)         # 원래 x도 모양을 바꿔준다.\n",
    "\n",
    "        # Affine 계층의 역전파를 수행한다.\n",
    "        db = np.sum(dout, axis=0)       \n",
    "        dW = np.dot(rx.T, dout)\n",
    "        dx = np.dot(dout, W.T)\n",
    "\n",
    "        dx = dx.reshape(*x.shape)       # 출력을 다시 원래 모양으로 바꿔준다.\n",
    "\n",
    "        self.grads[0][...] = dW         # 가중치 기울기 값을 저장한다.\n",
    "        self.grads[1][...] = db         # 편향 기울기 값을 저장한다.\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Time Embedding 계층도 T개의 Embedding 계층을 준비하고 각 Embedding 계층이 각 시각의 데이터를 처리하도록 만들면 된다.\n",
    "\n",
    "여기서 Embedding 계층 또한 학습이 되니까, word2vec에서 임베딩 계층을 들고오지 않아도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/common/time_layers.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-21\n",
    "\n",
    "Modified to work on jupyter notebook\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "class TimeEmbedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.layers = None\n",
    "        self.W = W\n",
    "\n",
    "    def forward(self, xs):\n",
    "        N, T = xs.shape\n",
    "        V, D = self.W.shape\n",
    "\n",
    "        out = np.empty((N, T, D), dtype='f')\n",
    "        self.layers = []\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = Embedding(self.W)                   # 여러개의 Embedding 계층을 만든다.\n",
    "            out[:, t, :] = layer.forward(xs[:, t])\n",
    "            self.layers.append(layer)                   # 역전파 시 활용하기 위해 저장한다.\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, T, D = dout.shape\n",
    "\n",
    "        grad = 0\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            layer.backward(dout[:, t, :])\n",
    "            grad += layer.grads[0]\n",
    "\n",
    "        self.grads[0][...] = grad\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Softmax with Loss는 다음과 같은 그림으로 나타낼 수 있다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-29.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{X}$는 아래 층에서 전해지는 점수이고, $\\mathbf{t}$는 해당 시각의 정답 레이블이다. 각각의 SoftmaxWithLoss를 통과한 loss $L$들의 합산 평균이 최종 Loss가 된다.\n",
    "\n",
    "$$\n",
    "L=\\frac{1}{T}(L_0+L_1+\\cdots+L_{T-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/common/time_layers.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-21\n",
    "\n",
    "Modified to work on jupyter notebook\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class TimeSoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.cache = None\n",
    "        self.ignore_label = -1\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        N, T, V = xs.shape\n",
    "\n",
    "        if ts.ndim == 3:  # 정답 레이블이 원핫 벡터인 경우\n",
    "            ts = ts.argmax(axis=2)\n",
    "\n",
    "        mask = (ts != self.ignore_label)\n",
    "\n",
    "        # 배치용과 시계열용을 정리(reshape)\n",
    "        \"\"\"  \n",
    "        Time Affine 계층처럼 동일하게 변형해서 softmax 연산을 한꺼번에 처리한다.\n",
    "        \"\"\"\n",
    "        xs = xs.reshape(N * T, V)\n",
    "        ts = ts.reshape(N * T)\n",
    "        mask = mask.reshape(N * T)\n",
    "\n",
    "        ys = softmax(xs)\n",
    "        ls = np.log(ys[np.arange(N * T), ts])\n",
    "        ls *= mask  # ignore_label에 해당하는 데이터는 손실을 0으로 설정\n",
    "        loss = -np.sum(ls)\n",
    "        loss /= mask.sum()\n",
    "\n",
    "        self.cache = (ts, ys, mask, (N, T, V))\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        ts, ys, mask, (N, T, V) = self.cache\n",
    "\n",
    "        dx = ys\n",
    "        dx[np.arange(N * T), ts] -= 1\n",
    "        dx *= dout\n",
    "        dx /= mask.sum()\n",
    "        dx *= mask[:, np.newaxis]  # ignore_label에 해당하는 데이터는 기울기를 0으로 설정\n",
    "\n",
    "        dx = dx.reshape((N, T, V))\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 RNNLM 학습과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/ch05/simple_rnnlm.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-21\n",
    "\n",
    "Modified to work on jupyter notebook\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from time_layers import *\n",
    "\n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화 - Xavier 초깃값을 이용한다.\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성 - 각각 layer가 선언되어 있다.\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다. - optimizer를 활용하기 위함이다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.2 언어 모델의 평가\n",
    "\n",
    "언어 모델의 예측 성능을 평가하는 척도로 **퍼플렉서티(perplexity, 혼란도)**를 이용한다.\n",
    "\n",
    "퍼플렉서티는 간단히 이야기하면 확률의 역수이다. 아래 그림의 예시가 있다고 해보자. \n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 5-32.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 1의 경우는 정답인 \"say\"의 확률이 0.8이고, 이때 퍼플렉서티는 $\\frac{1}{0.8}=1.25$이다. 모델 2의 경우는 정답인 \"say\"의 확률이 0.2이고, 퍼플렉서티는 $\\frac{1}{0.2}=5$이다. 모델 1이 모델 2에 비해 예측을 잘 했으므로, 퍼플렉서티가 작을 수록 좋다는 것을 알 수 있다.\n",
    "\n",
    "퍼플렉서티는 직관적으로 다음에 출현할 수 있는 단어의 후보 수인 \"분기 수\"로 해석할 수 있다. 모델 1의 경우는 다음에 출현할 수 있는 단어 수를 1.25개로 줄인 것이고, 모델 2의 경우는 다음에 출현할 수 있는 단어가 5개나 있기 때문에 줄이지 못했다고 볼 수 있다.\n",
    "\n",
    "입력 데이터가 여러 개일때 퍼플렉서티는 다음과 같이 계산할 수 있다.\n",
    "$$\n",
    "L = -\\frac{1}{N}\\sum_{n}\\sum_{k}t_{nk}\\log{y_{nk}} \\\\\n",
    "{perplexity}=e^{L}\n",
    "$$\n",
    "\n",
    "$N$은 데이터의 총 개수, $t_n$은 one-hot 벡터로 나타낸 정답 레이블, $t_{nk}$는 $n$개째 데이터의 $k$번째 값이다. $y_{nk}$는 신경망에서 Softmax의 출력이다. $L$은 종합해보면 신경망의 loss를 나타내고, $e^L$이 퍼플렉서티이다. 퍼플렉서티가 작아질수록 분기 수가 줄어들어 좋은 모델이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.3 RNNLM의 학습 코드\n",
    "\n",
    "PTB 데이터셋을 이용해 RNNLM을 학습히켜본다. PTB 데이터셋의 처음 1,000개만 이용해서 학습한다. 이 문제는 다음 장에서 개선한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말뭉치 크기: 1000, 어휘 수: 418\n",
      "| 에폭 1 | 퍼플렉서티 388.09\n",
      "| 에폭 2 | 퍼플렉서티 257.45\n",
      "| 에폭 3 | 퍼플렉서티 220.99\n",
      "| 에폭 4 | 퍼플렉서티 213.07\n",
      "| 에폭 5 | 퍼플렉서티 205.38\n",
      "| 에폭 6 | 퍼플렉서티 202.16\n",
      "| 에폭 7 | 퍼플렉서티 197.75\n",
      "| 에폭 8 | 퍼플렉서티 195.64\n",
      "| 에폭 9 | 퍼플렉서티 190.76\n",
      "| 에폭 10 | 퍼플렉서티 192.78\n",
      "| 에폭 11 | 퍼플렉서티 189.63\n",
      "| 에폭 12 | 퍼플렉서티 193.06\n",
      "| 에폭 13 | 퍼플렉서티 190.31\n",
      "| 에폭 14 | 퍼플렉서티 190.67\n",
      "| 에폭 15 | 퍼플렉서티 190.21\n",
      "| 에폭 16 | 퍼플렉서티 186.80\n",
      "| 에폭 17 | 퍼플렉서티 183.79\n",
      "| 에폭 18 | 퍼플렉서티 181.28\n",
      "| 에폭 19 | 퍼플렉서티 183.56\n",
      "| 에폭 20 | 퍼플렉서티 186.36\n",
      "| 에폭 21 | 퍼플렉서티 182.78\n",
      "| 에폭 22 | 퍼플렉서티 181.99\n",
      "| 에폭 23 | 퍼플렉서티 177.67\n",
      "| 에폭 24 | 퍼플렉서티 176.99\n",
      "| 에폭 25 | 퍼플렉서티 178.09\n",
      "| 에폭 26 | 퍼플렉서티 177.90\n",
      "| 에폭 27 | 퍼플렉서티 172.60\n",
      "| 에폭 28 | 퍼플렉서티 172.25\n",
      "| 에폭 29 | 퍼플렉서티 169.72\n",
      "| 에폭 30 | 퍼플렉서티 164.29\n",
      "| 에폭 31 | 퍼플렉서티 167.34\n",
      "| 에폭 32 | 퍼플렉서티 161.93\n",
      "| 에폭 33 | 퍼플렉서티 164.01\n",
      "| 에폭 34 | 퍼플렉서티 158.16\n",
      "| 에폭 35 | 퍼플렉서티 158.41\n",
      "| 에폭 36 | 퍼플렉서티 151.14\n",
      "| 에폭 37 | 퍼플렉서티 153.18\n",
      "| 에폭 38 | 퍼플렉서티 147.63\n",
      "| 에폭 39 | 퍼플렉서티 141.55\n",
      "| 에폭 40 | 퍼플렉서티 137.70\n",
      "| 에폭 41 | 퍼플렉서티 138.09\n",
      "| 에폭 42 | 퍼플렉서티 133.21\n",
      "| 에폭 43 | 퍼플렉서티 125.99\n",
      "| 에폭 44 | 퍼플렉서티 122.34\n",
      "| 에폭 45 | 퍼플렉서티 120.39\n",
      "| 에폭 46 | 퍼플렉서티 120.72\n",
      "| 에폭 47 | 퍼플렉서티 113.54\n",
      "| 에폭 48 | 퍼플렉서티 107.27\n",
      "| 에폭 49 | 퍼플렉서티 102.67\n",
      "| 에폭 50 | 퍼플렉서티 98.47\n",
      "| 에폭 51 | 퍼플렉서티 93.90\n",
      "| 에폭 52 | 퍼플렉서티 93.13\n",
      "| 에폭 53 | 퍼플렉서티 86.23\n",
      "| 에폭 54 | 퍼플렉서티 83.44\n",
      "| 에폭 55 | 퍼플렉서티 80.65\n",
      "| 에폭 56 | 퍼플렉서티 75.74\n",
      "| 에폭 57 | 퍼플렉서티 73.68\n",
      "| 에폭 58 | 퍼플렉서티 68.21\n",
      "| 에폭 59 | 퍼플렉서티 64.06\n",
      "| 에폭 60 | 퍼플렉서티 60.26\n",
      "| 에폭 61 | 퍼플렉서티 59.61\n",
      "| 에폭 62 | 퍼플렉서티 55.41\n",
      "| 에폭 63 | 퍼플렉서티 50.65\n",
      "| 에폭 64 | 퍼플렉서티 48.15\n",
      "| 에폭 65 | 퍼플렉서티 47.62\n",
      "| 에폭 66 | 퍼플렉서티 44.52\n",
      "| 에폭 67 | 퍼플렉서티 42.05\n",
      "| 에폭 68 | 퍼플렉서티 38.24\n",
      "| 에폭 69 | 퍼플렉서티 36.53\n",
      "| 에폭 70 | 퍼플렉서티 35.07\n",
      "| 에폭 71 | 퍼플렉서티 32.76\n",
      "| 에폭 72 | 퍼플렉서티 29.95\n",
      "| 에폭 73 | 퍼플렉서티 28.32\n",
      "| 에폭 74 | 퍼플렉서티 27.71\n",
      "| 에폭 75 | 퍼플렉서티 25.39\n",
      "| 에폭 76 | 퍼플렉서티 23.56\n",
      "| 에폭 77 | 퍼플렉서티 22.69\n",
      "| 에폭 78 | 퍼플렉서티 21.16\n",
      "| 에폭 79 | 퍼플렉서티 19.99\n",
      "| 에폭 80 | 퍼플렉서티 18.74\n",
      "| 에폭 81 | 퍼플렉서티 18.28\n",
      "| 에폭 82 | 퍼플렉서티 17.07\n",
      "| 에폭 83 | 퍼플렉서티 15.91\n",
      "| 에폭 84 | 퍼플렉서티 15.10\n",
      "| 에폭 85 | 퍼플렉서티 14.02\n",
      "| 에폭 86 | 퍼플렉서티 13.88\n",
      "| 에폭 87 | 퍼플렉서티 13.03\n",
      "| 에폭 88 | 퍼플렉서티 12.21\n",
      "| 에폭 89 | 퍼플렉서티 11.48\n",
      "| 에폭 90 | 퍼플렉서티 11.40\n",
      "| 에폭 91 | 퍼플렉서티 10.34\n",
      "| 에폭 92 | 퍼플렉서티 9.85\n",
      "| 에폭 93 | 퍼플렉서티 9.74\n",
      "| 에폭 94 | 퍼플렉서티 8.93\n",
      "| 에폭 95 | 퍼플렉서티 8.57\n",
      "| 에폭 96 | 퍼플렉서티 7.98\n",
      "| 에폭 97 | 퍼플렉서티 8.13\n",
      "| 에폭 98 | 퍼플렉서티 7.64\n",
      "| 에폭 99 | 퍼플렉서티 6.93\n",
      "| 에폭 100 | 퍼플렉서티 7.03\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/ch05/train_custom_loop.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-21\n",
    "\n",
    "Modified to work on jupyter notebook\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from optimizer import SGD\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5     # Truncated BPTT가 한 번에 펼치는 시간 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기(전체 중 1000개만)\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1]  # 입력\n",
    "ts = corpus[1:]   # 출력(정답 레이블)\n",
    "data_size = len(xs)\n",
    "print('말뭉치 크기: %d, 어휘 수: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 학습 시 사용하는 변수\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "\"\"\" 1번 부분 시작 \"\"\"\n",
    "# 미니배치의 각 샘플의 읽기 시작 위치를 계산\n",
    "jump = (corpus_size - 1) // batch_size              # 미니배치 크기만큼 점프 할 크기 계산\n",
    "offsets = [i * jump for i in range(batch_size)]     # 미니배치 별로 시작하는 데이터의 offset\n",
    "\"\"\" 1번 부분 끝 \"\"\"\n",
    "\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        \n",
    "        \"\"\" 2번 부분 시작 \"\"\"\n",
    "        # 미니배치 취득\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')      # batch_size x time_size의 행렬\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')      # batch_size x time_size의 행렬\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "        \"\"\" 2번 부분 끝 \"\"\"\n",
    "\n",
    "\n",
    "        # 기울기를 구하여 매개변수 갱신\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    \"\"\" 3번 부분 시작 \"\"\"\n",
    "    # 에폭마다 퍼플렉서티 평가\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| 에폭 %d | 퍼플렉서티 %.2f'\n",
    "          % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n",
    "    \"\"\" 3번 부분 끝 \"\"\"\n",
    "\n",
    "# 그래프 그리기\n",
    "x = np.arange(len(ppl_list))\n",
    "plt.plot(x, ppl_list, label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드의 2번 부분에 대한 좀 더 자세한 사항은 다음과 같다.\n",
    "\n",
    "<img src=\"./img/memo-5-3-3-batch-data.jpg\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
