{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 자연어와 단어의 분산 표현\n",
    "\n",
    "이번 장에서 할 내용:\n",
    "- 컴퓨터에게 말을 이해시키는 방법을 배워본다. 그 중에서도 딥러닝 등장 이전의 기법들\n",
    "- 파이썬으로 텍스트를 다루는 연습도 같이 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 자연어 처리란\n",
    "\n",
    "자연어(natural language): 우리가 평소에 쓰는 말\n",
    "자연어 처리(Natural Language Processing, NLP): 자연어를 컴퓨터에게 이해시키기 위한 분야\n",
    "\n",
    "대표적인 예시: 검색 엔진, 기계 번역, 질의응답 시스템, IME(입력기 전환), 문장 자동요약 등등(이것의 궁극적인 진화 버전이 chatGPT라고 보면 될 듯)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 단어의 의미\n",
    "\n",
    "'단어'는 의미의 최소 단위이다. '단어의 의미'를 컴퓨터에게 이해시키는 것이 중요하다.\n",
    "\n",
    "이번 장과 다음 장을 거쳐서 다음 세 의미를 알아보고자 한다.\n",
    "- thesaurus(유의어 사전)을 활용한 기법 (이번 장)\n",
    "- 통계 기반 기법 (이번 장)\n",
    "- 추론 기반 기법 (word2vec) (다음 장)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 thesaurus\n",
    "\n",
    "동의어를 그룹화해서 묶거나, 상위-하위, 전체-부분을 정의해놓기도 했다.\n",
    "\n",
    "동의어 집합을 만든 다음, 단어들의 관계를 그래프로 표현해 단어 사이의 연결을 정의한다.\n",
    "\n",
    "이 '단어 네트워크'를 이용해 컴퓨터에게 단어 사이의 관계를 가르쳤다.\n",
    "\n",
    "WordNet은 thesaurus 연구로, 많은 연구와 다양한 자연어 처리 애플리케이션에 사용되고 있다.\n",
    "\n",
    "thesaurus는 다음과 같은 문제점이 있다.\n",
    "- 시대 변화에 대응하기 어렵다\n",
    "- 사람을 쓰는 비용은 크다\n",
    "- 단어의 미묘한 차이를 표현할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 통계 기반 기법\n",
    "\n",
    "통계 기반 기법에서는 말뭉치(corpus)를 이용한다. 통계 기반 기법의 목표는 말뭉치에서 자동으로, 효율적으로 feature를 추출하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 파이썬으로 말뭉치 전처리하기\n",
    "\n",
    "전처리(preprocessing)은 텍스트 데이터를 단어로 분할하고 그 분할된 단어들을 단어 ID 목록으로 변환하는 일이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "Author: WegraLee\n",
    "Repository: deep-learning-from-sratch-2\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/common/util.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-19\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "\n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print(corpus)\n",
    "print(word_to_id)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 단어의 분산 표현\n",
    "\n",
    "'단어의 의미'를 정확하게 파악할 수 있도록 벡터 표현으로 나타낸 것이 단어의 분산 표현이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 분포 가설\n",
    "\n",
    "**분포 가설**은 '단어의 의미는 주변 단어에 의해 형성된다'라는 아이디어이다. 즉, 단어 자체에는 의미가 없고, 그 단어가 사용된 '맥락 context'이 의미를 형성한다는 것이다. \n",
    "\n",
    "여기서 맥락(context)는 주목하는 단어 주변에 놓인 단어를 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 동시발생 행렬\n",
    "\n",
    "분포 가설에 기반해 단어를 벡터로 나타내는 방법을 생각해보자.\n",
    "\n",
    "어떤 단어를 선택했을 때, 그 주변에 어떤 단어가 몇 번 등장했는지를 집계할 수 있다. 이를 일단 '통계 기반 기법'이라고 해보자.\n",
    "\n",
    "문장을 우선 전처리 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "print(corpus)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 단어별로 주변에 어떤 단어가 있는지를 표로 나타내면 다음과 같다.\n",
    "\n",
    "<img src=\"./deep_learning_2_images/fig 2-7.png\" width=\"50%\">\n",
    "\n",
    "이 표의 이름을 **동시발생 행렬**이라고 부른다.\n",
    "\n",
    "아래는 말뭉치로부터 동시발생 행렬을 구하는 걸 자동화한 파이썬 코드이다. 아래 코드는 말뭉치의 모든 단어 각각에 대해 주변 단어의 개수를 세아린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "Author: WegraLee\n",
    "Repository: deep-learning-from-sratch-2\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/common/util.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-19\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    '''동시발생 행렬 생성\n",
    "\n",
    "    :param corpus: 말뭉치(단어 ID 목록)\n",
    "    :param vocab_size: 어휘 수\n",
    "    :param window_size: 윈도우 크기(윈도우 크기가 1이면 타깃 단어 좌우 한 단어씩이 맥락에 포함)\n",
    "    :return: 동시발생 행렬\n",
    "    '''\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "\n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "\n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "\n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "co_matrix = create_co_matrix(corpus, len(word_to_id))\n",
    "print(co_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 벡터 간 유사도\n",
    "\n",
    "단어 벡터의 유사도를 나타내는 가장 좋은 방법은 cosine similarity이다. \n",
    "\n",
    "$$similarity(\\mathbf{x}, \\mathbf{y})={{\\mathbf{x} \\cdot \\mathbf{y}}\\over{||\\mathbf{x}||||\\mathbf{y}||}}$$\n",
    "\n",
    "아래에는 각 벡터의 norm을 구하는데, 이때 norm은 L2 norm(벡터의 각 원소를 제곱해서 더한 뒤 제곱근 취하기)를 사용한다.\n",
    "\n",
    "아래는 파이썬 코드로 작성한 cosine similarity이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "Author: WegraLee\n",
    "Repository: deep-learning-from-sratch-2\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/common/util.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-19\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    '''코사인 유사도 산출\n",
    "\n",
    "    :param x: 벡터\n",
    "    :param y: 벡터\n",
    "    :param eps: '0으로 나누기'를 방지하기 위한 작은 값\n",
    "    :return:\n",
    "    '''\n",
    "    nx = x / (np.sqrt(np.sum(x ** 2)) + eps)\n",
    "    ny = y / (np.sqrt(np.sum(y ** 2)) + eps)\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067691154799\n"
     ]
    }
   ],
   "source": [
    "# 단어 간 유사도를 구하는 코드\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "Author: WegraLee\n",
    "Repository: deep-learning-from-sratch-2\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/ch02/similarity.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-19\n",
    "\n",
    "Modified to work in jupyter notebook\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "c0 = C[word_to_id['you']]  # \"you\"의 단어 벡터\n",
    "c1 = C[word_to_id['i']]    # \"i\"의 단어 벡터\n",
    "print(cos_similarity(c0, c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 유사 단어의 랭킹 표시\n",
    "\n",
    "아래 코드는 어떤 단어와 가장 유사한 단어를 순위별로 반환하는 `most_similar()` 함수이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "Author: WegraLee\n",
    "Repository: deep-learning-from-sratch-2\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/common/util.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-19\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    '''유사 단어 검색\n",
    "\n",
    "    :param query: 쿼리(텍스트)\n",
    "    :param word_to_id: 단어에서 단어 ID로 변환하는 딕셔너리\n",
    "    :param id_to_word: 단어 ID에서 단어로 변환하는 딕셔너리\n",
    "    :param word_matrix: 단어 벡터를 정리한 행렬. 각 행에 해당 단어 벡터가 저장되어 있다고 가정한다.\n",
    "    :param top: 상위 몇 개까지 출력할 지 지정\n",
    "    '''\n",
    "    if query not in word_to_id:\n",
    "        print('%s(을)를 찾을 수 없습니다.' % query)\n",
    "        return\n",
    "\n",
    "    print('\\n[query] ' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    vocab_size = len(id_to_word)\n",
    "\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "\n",
    "    # 코사인 유사도를 기준으로 내림차순으로 출력\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
    "\n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0]\n"
     ]
    }
   ],
   "source": [
    "# argsort() 함수 설명\n",
    "# argsort()는 np.array 속 원소를 오름차순으로 정렬한 다음, 정렬된 index를 반환한다.\n",
    "x = np.array([100, -20, 2])\n",
    "print(x.argsort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " goodbye: 0.7071067691154799\n",
      " i: 0.7071067691154799\n",
      " hello: 0.7071067691154799\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "# \"you\"를 검색어로 지정해 유사한 단어들을 출력함\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "Author: WegraLee\n",
    "Repository: deep-learning-from-sratch-2\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/ch02/most_similar.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-19\n",
    "\n",
    "Modified to work on jupyter notebook\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "most_similar('you', word_to_id, id_to_word, C, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 통계 기반 기법 개선하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 상호정보량\n",
    "\n",
    "동시발생 행렬에서 \"발생\" 횟수는 좋은 feature는 아니다. \"the car\"라는 말이 많이 사용되지만 \"the\"와 \"car\"는 연관성이 크지 않기 때문이다. \n",
    "\n",
    "이를 개선하기 위해 **점별 상호정보량(Pointwise Mutual Informaion, PMI)**를 사용한다. PMI는 확률변수 $x$와 확률변수 $y$에 대해 다음과 같이 정의된다. \n",
    "$$PMI(x, y)=\\log_2{{P(x,y)}\\over{P(x)P(y)}}$$\n",
    "$P(x), P(y)$는 x, y가 일어날 확률, $P(x,y)$는 x, y가 동시에 일어날 확률이다. PMI 값이 높을수록 두 확률변수 x, y 사이 관련성이 높다. \n",
    "\n",
    "이를 앞서 본 동시발생 행렬 $C$로 바꾸면, $C(x), C(y)$는 x와 y가 나타난 횟수, $C(x,y)$는 x와 y가 동시발생한 횟수이다. PMI를 $C$에 기반해 바꾸면 다음과 같다. \n",
    "$$PMI(x, y)=\\log_2{{P(x,y)}\\over{P(x)P(y)}}=\\log_2{{C(x,y) \\cdot N}\\over{C(x)C(y)}}$$\n",
    "\n",
    "PMI를 실제로 구현했을 때, 두 단어의 동시발생 횟수가 0이면 $\\log_20$ 문제가 생기므로, Positive PMI(PPMI)를 정의해 사용한다.\n",
    "$$PPMI(x,y)=\\max(0, PMI(x,y))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "Author: WegraLee\n",
    "Repository: deep-learning-from-sratch-2\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/common/util.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-19\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "def ppmi(C, verbose=False, eps = 1e-8):\n",
    "    '''PPMI(점별 상호정보량) 생성\n",
    "\n",
    "    :param C: 동시발생 행렬\n",
    "    :param verbose: 진행 상황을 출력할지 여부\n",
    "    :return:\n",
    "    '''\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[j]*S[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "\n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100 + 1) == 0:\n",
    "                    print('%.1f%% 완료' % (100*cnt/total))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생 행렬\n",
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "--------------------------------------------------\n",
      "PPMI\n",
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.807 0.    0.    0.    0.    2.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "# 동시발생 행렬을 PPMI 행렬로 변환하는 코드\n",
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "Author: WegraLee\n",
    "Repository: deep-learning-from-sratch-2\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/ch02/ppmi.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-19\n",
    "\n",
    "Modified to work on jupyter notebook\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "W = ppmi(C)\n",
    "\n",
    "np.set_printoptions(precision=3)  # 유효 자릿수를 세 자리로 표시\n",
    "print('동시발생 행렬')\n",
    "print(C)\n",
    "print('-'*50)\n",
    "print('PPMI')\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPMI 행렬은 corpus의 어휘 수가 늘어날수록 각 단어 벡터의 차원수가 늘어난다는 문제점이 있다.\n",
    "\n",
    "또한, 원소 대부분이 0의 값을 가지므로, 원소별 중요도가 낮고, 노이즈에 약하고 견고하지 못하다.\n",
    "\n",
    "이에 대응하기 위한 개념이 dimensionality reduction이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 차원 감소\n",
    "\n",
    "**차원 감소(dimensionality reduction)** 는 중요한 정보를 최대한 유지하면서 벡터의 차원을 줄이는 기법이다. \n",
    "\n",
    "다음 그림은 차원 감소를 나타내는 그림이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./deep_learning_2_images/fig 2-8.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "차원 감소에 사용되는 방법 중 하나는 **특잇값분해(Singular Value Decomposition)** 를 사용한다.\n",
    "\n",
    "SVD는 임의의 행렬을 세 행렬의 곱으로 분해한다. \n",
    "\n",
    "$$\\mathbf{X}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^T$$\n",
    "\n",
    "$\\mathbf{U}$와 $\\mathbf{V}$는 orthogonal matrix(직교행렬)이고, 열벡터는 서로 직교한다. $\\mathbf{S}$는 대각행렬(diagonal matrix)이다. \n",
    "\n",
    "$\\mathbf{U}$ 행렬을 '단어 공간'으로 생각한다. $\\mathbf{S}$의 대각성분에는 특잇값(singular value)가 큰 순서대로 나열되어 있다. 특잇값은 '해당 축'의 중요도를 나타낸다. 따라서, 아래 그림처럼 중요하지 않은 부분인 뒷 부분을 깎아낸 행렬을 생각할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./deep_learning_2_images/fig 2-10.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 단어 공간으로 바꾸면, $\\mathbf{X}$의 각 행에는 해당 단어 ID의 단어 벡터가 저장되어 있고, 이들은 $\\mathbf{U}'$라는 차원 감소된 벡터로 표현된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 SVD에 의한 차원 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0]\n",
      "[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      "[ 0.000e+00  3.409e-01 -1.205e-01 -3.886e-16 -9.323e-01  0.000e+00\n",
      " -1.086e-16]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SVD 차원 감소 코드\n",
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "Author: WegraLee\n",
    "Repository: deep-learning-from-sratch-2\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/ch02/ppmi.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-19\n",
    "\n",
    "Modified to work on jupyter notebook\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(id_to_word)\n",
    "C = create_co_matrix(corpus, vocab_size, window_size=1)\n",
    "W = ppmi(C)\n",
    "\n",
    "# SVD\n",
    "U, S, V = np.linalg.svd(W)\n",
    "\n",
    "np.set_printoptions(precision=3)  # 유효 자릿수를 세 자리로 표시\n",
    "print(C[0])\n",
    "print(W[0])\n",
    "print(U[0])\n",
    "\n",
    "# 플롯\n",
    "for word, word_id in word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "plt.scatter(U[:,0], U[:,1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.4 PTB 데이터셋\n",
    "\n",
    "**펜 트리뱅크(PTB)** 를 corpus로 이용해보자.\n",
    "\n",
    "dataset/ptb.py를 저장해두어서 사용할 수 있도록 만들었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말뭉치 크기: 929589\n",
      "corpus[:30]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "id_to_word[0]: aer\n",
      "id_to_word[1]: banknote\n",
      "id_to_word[2]: berlitz\n",
      "\n",
      "word_to_id['car']: 3856\n",
      "word_to_id['happy']: 4428\n",
      "word_to_id['lexus']: 7426\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "Author: WegraLee\n",
    "Repository: deep-learning-from-sratch-2\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/ch02/show_ptb.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-19\n",
    "\n",
    "Modified to work on jupyter notebook\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "from dataset import ptb\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "print('말뭉치 크기:', len(corpus))\n",
    "print('corpus[:30]:', corpus[:30])\n",
    "print()\n",
    "print('id_to_word[0]:', id_to_word[0])\n",
    "print('id_to_word[1]:', id_to_word[1])\n",
    "print('id_to_word[2]:', id_to_word[2])\n",
    "print()\n",
    "print(\"word_to_id['car']:\", word_to_id['car'])\n",
    "print(\"word_to_id['happy']:\", word_to_id['happy'])\n",
    "print(\"word_to_id['lexus']:\", word_to_id['lexus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.5 PTB 데이터셋 평가\n",
    "\n",
    "빠른 SVD를 위해서는 `sklearn` 모듈을 설치하면 된다. (`sklearn` 모듈은 이전 이름으로, 지금은 `scikit-learn`을 설치하면 된다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생 수 계산 ...\n",
      "PPMI 계산 ...\n",
      "1.0% 완료\n",
      "2.0% 완료\n",
      "3.0% 완료\n",
      "4.0% 완료\n",
      "5.0% 완료\n",
      "6.0% 완료\n",
      "7.0% 완료\n",
      "8.0% 완료\n",
      "9.0% 완료\n",
      "10.0% 완료\n",
      "11.0% 완료\n",
      "12.0% 완료\n",
      "13.0% 완료\n",
      "14.0% 완료\n",
      "15.0% 완료\n",
      "16.0% 완료\n",
      "17.0% 완료\n",
      "18.0% 완료\n",
      "19.0% 완료\n",
      "20.0% 완료\n",
      "21.0% 완료\n",
      "22.0% 완료\n",
      "23.0% 완료\n",
      "24.0% 완료\n",
      "25.0% 완료\n",
      "26.0% 완료\n",
      "27.0% 완료\n",
      "28.0% 완료\n",
      "29.0% 완료\n",
      "30.0% 완료\n",
      "31.0% 완료\n",
      "32.0% 완료\n",
      "33.0% 완료\n",
      "34.0% 완료\n",
      "35.0% 완료\n",
      "36.0% 완료\n",
      "37.0% 완료\n",
      "38.0% 완료\n",
      "39.0% 완료\n",
      "40.0% 완료\n",
      "41.0% 완료\n",
      "42.0% 완료\n",
      "43.0% 완료\n",
      "44.0% 완료\n",
      "45.0% 완료\n",
      "46.0% 완료\n",
      "47.0% 완료\n",
      "48.0% 완료\n",
      "49.0% 완료\n",
      "50.0% 완료\n",
      "51.0% 완료\n",
      "52.0% 완료\n",
      "53.0% 완료\n",
      "54.0% 완료\n",
      "55.0% 완료\n",
      "56.0% 완료\n",
      "57.0% 완료\n",
      "58.0% 완료\n",
      "59.0% 완료\n",
      "60.0% 완료\n",
      "61.0% 완료\n",
      "62.0% 완료\n",
      "63.0% 완료\n",
      "64.0% 완료\n",
      "65.0% 완료\n",
      "66.0% 완료\n",
      "67.0% 완료\n",
      "68.0% 완료\n",
      "69.0% 완료\n",
      "70.0% 완료\n",
      "71.0% 완료\n",
      "72.0% 완료\n",
      "73.0% 완료\n",
      "74.0% 완료\n",
      "75.0% 완료\n",
      "76.0% 완료\n",
      "77.0% 완료\n",
      "78.0% 완료\n",
      "79.0% 완료\n",
      "80.0% 완료\n",
      "81.0% 완료\n",
      "82.0% 완료\n",
      "83.0% 완료\n",
      "84.0% 완료\n",
      "85.0% 완료\n",
      "86.0% 완료\n",
      "87.0% 완료\n",
      "88.0% 완료\n",
      "89.0% 완료\n",
      "90.0% 완료\n",
      "91.0% 완료\n",
      "92.0% 완료\n",
      "93.0% 완료\n",
      "94.0% 완료\n",
      "95.0% 완료\n",
      "96.0% 완료\n",
      "97.0% 완료\n",
      "98.0% 완료\n",
      "99.0% 완료\n",
      "calculating SVD ...\n",
      "\n",
      "[query] you\n",
      " i: 0.700317919254303\n",
      " we: 0.6367185115814209\n",
      " anybody: 0.565764307975769\n",
      " do: 0.563567042350769\n",
      " 'll: 0.5127798318862915\n",
      "\n",
      "[query] year\n",
      " month: 0.6961644291877747\n",
      " quarter: 0.6884941458702087\n",
      " earlier: 0.6663320660591125\n",
      " last: 0.6281364560127258\n",
      " next: 0.6175755858421326\n",
      "\n",
      "[query] car\n",
      " luxury: 0.6728832125663757\n",
      " auto: 0.6452109813690186\n",
      " vehicle: 0.6097723245620728\n",
      " cars: 0.6032834053039551\n",
      " corsica: 0.5698372721672058\n",
      "\n",
      "[query] toyota\n",
      " motor: 0.7585658431053162\n",
      " nissan: 0.7148030996322632\n",
      " motors: 0.692615807056427\n",
      " lexus: 0.6583304405212402\n",
      " honda: 0.6350275278091431\n"
     ]
    }
   ],
   "source": [
    "# 느린 SVD: numpy SVD를 이용\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "Author: WegraLee\n",
    "Repository: deep-learning-from-sratch-2\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/ch02/count_method_big.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-19\n",
    "\n",
    "Modified to work on jupyter notebook\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "from dataset import ptb\n",
    "\n",
    "window_size = 2\n",
    "wordvec_size = 100\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print('동시발생 수 계산 ...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('PPMI 계산 ...')\n",
    "W = ppmi(C, verbose=True)\n",
    "\n",
    "print('calculating SVD ...')\n",
    "\n",
    "# numpy SVD\n",
    "U, S, V = np.linalg.svd(W)\n",
    "\n",
    "word_vecs = U[:, :wordvec_size]\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생 수 계산 ...\n",
      "PPMI 계산 ...\n",
      "1.0% 완료\n",
      "2.0% 완료\n",
      "3.0% 완료\n",
      "4.0% 완료\n",
      "5.0% 완료\n",
      "6.0% 완료\n",
      "7.0% 완료\n",
      "8.0% 완료\n",
      "9.0% 완료\n",
      "10.0% 완료\n",
      "11.0% 완료\n",
      "12.0% 완료\n",
      "13.0% 완료\n",
      "14.0% 완료\n",
      "15.0% 완료\n",
      "16.0% 완료\n",
      "17.0% 완료\n",
      "18.0% 완료\n",
      "19.0% 완료\n",
      "20.0% 완료\n",
      "21.0% 완료\n",
      "22.0% 완료\n",
      "23.0% 완료\n",
      "24.0% 완료\n",
      "25.0% 완료\n",
      "26.0% 완료\n",
      "27.0% 완료\n",
      "28.0% 완료\n",
      "29.0% 완료\n",
      "30.0% 완료\n",
      "31.0% 완료\n",
      "32.0% 완료\n",
      "33.0% 완료\n",
      "34.0% 완료\n",
      "35.0% 완료\n",
      "36.0% 완료\n",
      "37.0% 완료\n",
      "38.0% 완료\n",
      "39.0% 완료\n",
      "40.0% 완료\n",
      "41.0% 완료\n",
      "42.0% 완료\n",
      "43.0% 완료\n",
      "44.0% 완료\n",
      "45.0% 완료\n",
      "46.0% 완료\n",
      "47.0% 완료\n",
      "48.0% 완료\n",
      "49.0% 완료\n",
      "50.0% 완료\n",
      "51.0% 완료\n",
      "52.0% 완료\n",
      "53.0% 완료\n",
      "54.0% 완료\n",
      "55.0% 완료\n",
      "56.0% 완료\n",
      "57.0% 완료\n",
      "58.0% 완료\n",
      "59.0% 완료\n",
      "60.0% 완료\n",
      "61.0% 완료\n",
      "62.0% 완료\n",
      "63.0% 완료\n",
      "64.0% 완료\n",
      "65.0% 완료\n",
      "66.0% 완료\n",
      "67.0% 완료\n",
      "68.0% 완료\n",
      "69.0% 완료\n",
      "70.0% 완료\n",
      "71.0% 완료\n",
      "72.0% 완료\n",
      "73.0% 완료\n",
      "74.0% 완료\n",
      "75.0% 완료\n",
      "76.0% 완료\n",
      "77.0% 완료\n",
      "78.0% 완료\n",
      "79.0% 완료\n",
      "80.0% 완료\n",
      "81.0% 완료\n",
      "82.0% 완료\n",
      "83.0% 완료\n",
      "84.0% 완료\n",
      "85.0% 완료\n",
      "86.0% 완료\n",
      "87.0% 완료\n",
      "88.0% 완료\n",
      "89.0% 완료\n",
      "90.0% 완료\n",
      "91.0% 완료\n",
      "92.0% 완료\n",
      "93.0% 완료\n",
      "94.0% 완료\n",
      "95.0% 완료\n",
      "96.0% 완료\n",
      "97.0% 완료\n",
      "98.0% 완료\n",
      "99.0% 완료\n",
      "calculating SVD ...\n",
      "\n",
      "[query] you\n",
      " i: 0.6967585682868958\n",
      " we: 0.6155701875686646\n",
      " 'd: 0.5936014652252197\n",
      " 'll: 0.5503091216087341\n",
      " somebody: 0.5343175530433655\n",
      "\n",
      "[query] year\n",
      " month: 0.640466570854187\n",
      " quarter: 0.6171438694000244\n",
      " next: 0.5751550197601318\n",
      " months: 0.572130024433136\n",
      " last: 0.5546457767486572\n",
      "\n",
      "[query] car\n",
      " luxury: 0.5582557916641235\n",
      " auto: 0.5501270890235901\n",
      " corsica: 0.513378381729126\n",
      " cars: 0.5114415287971497\n",
      " truck: 0.4928312301635742\n",
      "\n",
      "[query] toyota\n",
      " nissan: 0.6867485642433167\n",
      " motor: 0.6833123564720154\n",
      " motors: 0.6493730545043945\n",
      " honda: 0.6291057467460632\n",
      " mazda: 0.5924068689346313\n"
     ]
    }
   ],
   "source": [
    "# 빠른 SVD: scikit-learn 모듈을 이용\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Code Source:\n",
    "Author: WegraLee\n",
    "Repository: deep-learning-from-sratch-2\n",
    "URL: https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/ch02/count_method_big.py\n",
    "License: MIT License\n",
    "Accessed: 2024-11-19\n",
    "\n",
    "Modified to work on jupyter notebook\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "from dataset import ptb\n",
    "\n",
    "window_size = 2\n",
    "wordvec_size = 100\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print('동시발생 수 계산 ...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('PPMI 계산 ...')\n",
    "W = ppmi(C, verbose=True)\n",
    "\n",
    "print('calculating SVD ...')\n",
    "\n",
    "# numpy SVD\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5,\n",
    "                         random_state=None)\n",
    "\n",
    "word_vecs = U[:, :wordvec_size]\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 정리\n",
    "\n",
    "컴퓨터에게 '단어의 의미'를 이해시키기 위해 thesaurus 기법을 먼저 보고, 통계 기반 기법을 살펴봤다.\n",
    "\n",
    "thesaurus 기법은 사람의 수작업이 들어가서 매우 힘든 작업이 된다. 통계 기반 기법은 corpus에서 단어의 의미를 자동으로 추출하고, 그 의미를 벡터로 표현한다. 단어의 동시발생 행렬을 만들고, PPMI 행렬로 변환한 다음, SVD를 이용해 차원을 감소시켜 각 단어의 분산 표현을 만들어냈다. 그 결과 비슷한 단어들이 벡터 공간에서도 서로 가까이 모여있었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
